{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import glob\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense,GlobalAveragePooling2D,Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting useful images from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob (\"./images/*.png\")\n",
    "files = np.asarray(files)\n",
    "data_train = pd.read_csv(\"training.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "Y_training = data_train.iloc[:,1:]\n",
    "X_training = data_train.iloc[:,0:1]\n",
    "Y_testing = data_test.iloc[:,1:]\n",
    "X_testing = data_test.iloc[:,0:1]\n",
    "collectionArr = files\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train =[]\n",
    "Y_test = []\n",
    "counter = 0\n",
    "for each in collectionArr:\n",
    "    image_name = each.split('/')[2]\n",
    "    indexer1 = X_training.index[X_training['image_name'] == image_name]\n",
    "    indexer2 = X_testing.index[X_testing['image_name']== image_name]\n",
    "    if(indexer1.empty):\n",
    "        pass\n",
    "    else:\n",
    "        X_train.append(each)\n",
    "        Y_train.append(Y_training.iloc[indexer1,:].values)\n",
    "    if(indexer2.empty):\n",
    "        pass\n",
    "    else:\n",
    "        X_test.append(each)\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "np.save('X_train',X_train)\n",
    "np.save('Y_train',Y_train)\n",
    "np.save('X_test',X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.load('X_train.npy')\n",
    "X64 = []\n",
    "for myFile in files:\n",
    "    image = cv2.imread (myFile)\n",
    "    image = cv2.cvtColor( image, cv2.COLOR_RGB2GRAY )\n",
    "    resized64 = cv2.resize(image,(192,192))\n",
    "    X64.append (resized64)\n",
    "    \n",
    "X64 = np.asarray(X64)\n",
    "print(X64.shape)\n",
    "np.save(\"Train_Processed_192\",X64)\n",
    "\n",
    "files = np.load('X_test.npy')\n",
    "X64_test = []\n",
    "for myFile in files:\n",
    "    image = cv2.imread (myFile)\n",
    "    image = cv2.cvtColor( image, cv2.COLOR_RGB2GRAY )\n",
    "    resized64 = cv2.resize(image,(192,192))\n",
    "    X64_test.append (resized64)\n",
    "    \n",
    "X64_test = np.asarray(X64_test)\n",
    "print(X64_test.shape)\n",
    "np.save(\"Train_Processed_192\",X64_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and scaling the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscale = 192/640\n",
    "yscale = 192/480\n",
    "X_train = np.load('./Train_Processed_192.npy')\n",
    "Y_train = np.load('./Y_train.npy')\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "Y_train_new = []\n",
    "for i in range(0,Y_train.shape[0]):\n",
    "    Y_train_new.append(Y_train[i][0])\n",
    "Y_train_new = np.asarray(Y_train_new)\n",
    "print(Y_train_new.shape)\n",
    "print(Y_train_new.shape[0])\n",
    "for i in range(0,Y_train_new.shape[0]):\n",
    "    Y_train_new[i][0] = Y_train_new[i][0] * xscale\n",
    "    Y_train_new[i][1] = Y_train_new[i][1] * xscale\n",
    "    Y_train_new[i][2] = Y_train_new[i][2] * yscale\n",
    "    Y_train_new[i][3] = Y_train_new[i][3] * yscale\n",
    "X_train = X_train/255\n",
    "mean = np.mean(X_train,axis=0)\n",
    "std = np.std(X_train,axis=0)\n",
    "print(\"Before \",mean.shape,std.shape)\n",
    "X_train = X_train - mean\n",
    "X_train = X_train / std\n",
    "print(\"After \",X_train.mean(),X_train.std())\n",
    "np.save(\"mean.npy\",mean)\n",
    "np.save(\"std.npy\",std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape = (192,192,1))\n",
    "# Block 1\n",
    "x = layers.Conv2D(64, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block1_conv1')(input_1)\n",
    "x = layers.Conv2D(64, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block1_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = layers.Conv2D(128, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block2_conv1')(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block2_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Block 3\n",
    "x = layers.Conv2D(256, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block3_conv1')(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block3_conv2')(x)\n",
    "\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Block 4\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block4_conv1')(x)\n",
    "\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block4_conv2')(x)\n",
    "\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "# Block 5\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block5_conv1')(x)\n",
    "\n",
    "x = layers.Conv2D(512, (3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  name='block5_conv2')(x)\n",
    "\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(4,kernel_initializer='normal')(x)\n",
    "model = Model(inputs=input_1, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#rms = optimizers.RMSprop(lr=0.0001, rho=0.9)\n",
    "adm = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='mean_squared_error', optimizer=adm,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True,period=1)\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=3,verbose=1, mode='auto',restore_best_weights=True)\n",
    "callbacks_list = [earlystop,checkpoint]\n",
    "history=model.fit(X_train,Y_train_new, validation_split = 0.2 , batch_size = 8, callbacks = callbacks_list,epochs =35,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the graph of Training Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the weights of the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Best_Model10.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
